---
title: "LLM Infra Issue Debug"
published: 2026-2-12
description: LLM Infra Issue Debug
tags: [ai infra]
category: ai infra
draft: false
---
# LLM Infra Issue Debug

## OOM堆栈不准

GPU执行kernel是异步的，报错堆栈可能不准确。

设置环境变量让GPU同步执行，获得准确堆栈：


```bash
export CUDA_LAUNCH_BLOCKING=1
```

## decode阶段CUDA Graph

decode开启CUDA Graph时，OOM可能在 `replay` 时报错，无法定位具体算子，需要禁用后复现：

```bash
python -m sglang.launch_server --model-path /path/to/model --disable-cuda-graph
```

## GPU死锁

### py-spy查看线程栈

```bash
py-spy dump -p <pid>
```

### 判断GPU任务卡住

CPU卡在同步任务（如`.tolist()` ）时，如果GPU核心100%满载且无波动，说明GPU任务卡住。

### cuda-gdb查看GPU栈

```bash
cuda-gdb -p <pid>

(gdb) bt
```

### 环境不匹配

如果bt卡在CUDA的.so动态库，说明nvcc/CUDA驱动/torch runtime版本不匹配。

```bash
nvcc -V

pip show nvidia-cuda-runtime-cu12
```

保持小版本号一致（如都是12.8），升级后重新编译卡住的库：

```bash
python setup.py install
```

